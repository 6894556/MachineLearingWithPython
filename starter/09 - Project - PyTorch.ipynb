{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef5edb03",
   "metadata": {},
   "source": [
    "### Step 1: Install Torch\n",
    "- Execute the following cell which will install **torch** and **torchvision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3086f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8bc9a2",
   "metadata": {},
   "source": [
    "### Step 2: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "061d96fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have tried out to take the one from \n",
    "# tensorflow and transform it into here and see how it went.\n",
    "# Please let me know int the comments.\n",
    "\n",
    "# Go as far as you can.\n",
    "# Then I'll help you.\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a4ae5",
   "metadata": {},
   "source": [
    "### Step 3: Download the CIFAR10 dataset\n",
    "- Excute the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f73edbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = '/downloads/'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True) # train set\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True) # valdiation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1bd0ca",
   "metadata": {},
   "source": [
    "### Step 4: Explore the dataset\n",
    "- See the type of **cifar10**\n",
    "- Get the length of **cifar10**\n",
    "- Assign image and label of **cifar10** at index 1000\n",
    "- Get the class name of label\n",
    "    - HINT: Use **cifar10.classes[label]** to get the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbfa245d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.cifar.CIFAR10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "611c1319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar10), len(cifar10_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d23105a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'truck'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 1000\n",
    "image, label = cifar[index]\n",
    "cifar.classes[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab645542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65639015",
   "metadata": {},
   "source": [
    "### Step 5: Visualize the image\n",
    "- Use **matplotlib** to visuazlize image\n",
    "    - HINT: just use **plt.imshow(...)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7972f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(image) # not cmap options since cifar10 is consist of color images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31377c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8005d75d",
   "metadata": {},
   "source": [
    "### Step 6: Transform images\n",
    "- We need to convert the PIL image to a PyTorch tensor\n",
    "- We can easily transform it by adding **transform=transforms.ToTensor()** when reading the dataset.\n",
    "- This is given below (just execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae7ff28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_cifar10 = datasets.CIFAR10(data_path, train=True,\n",
    "                         download=False,\n",
    "                        transform=transforms.ToTensor()) # train set\n",
    "\"\"\"\n",
    "tensor_cifar10_val = datasets.CIFAR10(data_path,\n",
    "                             train=False,\n",
    "                             download=False,\n",
    "                            transform=transforms.ToTensor()) # valdiation set\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfaae34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe65a981",
   "metadata": {},
   "source": [
    "### Step 7: Normalize images\n",
    "- Now you have all images (transformed) in **tensor_cifar10**.\n",
    "- To concatenate a stack of images use **torch.stack(..., dim=3)** on the images\n",
    "    - HINT: Use list comprehension to get a list of images from **tensor_cifar10** (to exclude labels)\n",
    "- Calculate the **mean(dim=1)** by applying it on the stack\n",
    "- Calculate the **std(dim=1)** by applying it on the stack\n",
    "- We will use the results in next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ab100f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcb9d040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4914, 0.4822, 0.4465])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.view(3, -1).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c211f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2470, 0.2435, 0.2616])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.view(3, -1).std(dim=1)\n",
    "# now we have the values which we are going to use down below.\n",
    "# we have a value from each layer or frame or images.\n",
    "# recall grayscale images have only one layer.\n",
    "# but now we have red, blue, green.\n",
    "# we have three layers of the colors and we have a value from each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d298703f",
   "metadata": {},
   "source": [
    "### Step 8: Normalize the data\n",
    "- We can add a normalize transform with adding a **transforms.Compose([...])**, where the list will contain the transforms.\n",
    "- The transform we want are **transforms.ToTensor()** and **transforms.Normalize(...)**\n",
    "    - HINT: See lesson how it was done\n",
    "- The **transforms.Normalize(...)** takes two tuples of the results from last step.\n",
    "    - Note: that in the lesson it was single numbers, here we hare tuples.\n",
    "- Read the datasets to **cifar10** with the new transform\n",
    "- Read the validation dataset to **cifar10_val** with the new transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e64a4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = datasets.CIFAR10(data_path,\n",
    "                          train=True,\n",
    "                          download=False,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                                  (0.4914, 0.4822, 0.4465))\n",
    "                          ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d716038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this for the validation as well.\n",
    "cifar10_val = datasets.CIFAR10(data_path,\n",
    "                          train=False,\n",
    "                          download=False,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                                  (0.4914, 0.4822, 0.4465))\n",
    "                          ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ef2dcd",
   "metadata": {},
   "source": [
    "### Step 9: Limit the dataset\n",
    "- There are 10 classes in this dataset - to simplify, we will reduce it to two\n",
    "- We will keep label 0 and 2 (**'airplane'** and **'bird'**)\n",
    "- Use list comprehension to filter the datasets.\n",
    "    - To simplify use a **label_map = {0: 0, 2: 1}**, which is used to map label 0 to 0 and label 2 to 1.\n",
    "    - Then use list comprehension **[(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]**\n",
    "    - And similar for **cifar10_val**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90047549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what we need to do : extract all the information from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be1fb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해설:\n",
    "# (1) it takes images and labels from cifar10 if label in [0, 2]\n",
    "# (2) we map. if it was 2 then it will be mappped to 1\n",
    "# (3) and if it's a 0 it will be mapped to 0.\n",
    "\n",
    "# CIFAR2: because there are only two different categories now.\n",
    "# cifar10을 실행하고 이 cell을 실행해야함.\n",
    "label_map = {0:0, 2:1}\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bb3eac",
   "metadata": {},
   "source": [
    "### Step 10: Create the model\n",
    "- We create a simple model here\n",
    "    - 3072 input nodes -> Linear with 512 nodes (Tanh acitivation)  -> Linear with 2 nodes (LogSoftmax activation)\n",
    "- To do that use **nn.Sequential(...)** with the following arguments.\n",
    "    - **nn.Linear(3072, 512)**\n",
    "        - Bonus question: Why 3072 input nodes?\n",
    "    - **nn.Tanh()**\n",
    "    - **nn.Linear(512, 2)**\n",
    "    - **nn.LogSoftmax(dim=1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4eafc651",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(3072, 512),\n",
    "                     nn.Tanh(),\n",
    "                     nn.Linear(512, 2),\n",
    "                     nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a5f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf32440f",
   "metadata": {},
   "source": [
    "### Step 11: Train the model\n",
    "- Prepare training data\n",
    "\n",
    "```Python\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "```\n",
    "\n",
    "- Set the **learning_rate = 0.01** (to make it easy to adjust)\n",
    "- Prepare optimizer and loss function.\n",
    "\n",
    "```Python\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "```\n",
    "\n",
    "- Run the training\n",
    "\n",
    "```Python\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a790adfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.467139\n",
      "Epoch: 1, Loss: 0.330232\n",
      "Epoch: 2, Loss: 0.634649\n",
      "Epoch: 3, Loss: 0.789560\n",
      "Epoch: 4, Loss: 0.483002\n",
      "Epoch: 5, Loss: 0.384082\n",
      "Epoch: 6, Loss: 0.485912\n",
      "Epoch: 7, Loss: 0.407590\n",
      "Epoch: 8, Loss: 0.299045\n",
      "Epoch: 9, Loss: 0.506901\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3297c63d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92a127ed",
   "metadata": {},
   "source": [
    "### Step 12: Test the model\n",
    "- Run the following code (where we assume the test data is called **cifar10_val** and the model **model**.\n",
    "```Python\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "print(\"Accuracy: %f\", correct / total)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f05ad0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: %f 0.8075\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                       shuffle=False)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "  for imgs, labels in val_loader:\n",
    "      batch_size = imgs.shape[0]\n",
    "      outputs = model(imgs.view(batch_size, -1))\n",
    "      _, predicted = torch.max(outputs, dim=1)\n",
    "      total += labels.shape[0]\n",
    "      correct += int((predicted == labels).sum())\n",
    "print(\"Accuracy: %f\", correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b133acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99161df7",
   "metadata": {},
   "source": [
    "### Step 13 (Optional): Improve the model\n",
    "- Try to improve the model\n",
    "    - Simple things you can play with\n",
    "        - Adjust the learning rate\n",
    "        - Run more epochs\n",
    "        - Number of hidden nodes\n",
    "    - Medium things to play with\n",
    "        - Change activation functions\n",
    "        - Add another layer\n",
    "    - Advanced things\n",
    "        - Let your imagination guide you\n",
    "        - For inspiration see state of the art results ([wiki](https://en.wikipedia.org/wiki/CIFAR-10#Research_papers_claiming_state-of-the-art_results_on_CIFAR-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77dac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# people say PyTorch is more in line with how you should think Python.\n",
    "# timeseries data: data that has sequence of time in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69774be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f103c9c",
   "metadata": {},
   "source": [
    "### Step 14 (Optional): Add more classes\n",
    "- The dataset was limited to two classes (**airplane**s and **bird**s)\n",
    "- Try to add another class (or more) and see how it changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65c060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37e5bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
