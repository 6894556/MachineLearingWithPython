{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b8fe662",
   "metadata": {},
   "source": [
    "# Project - Perceptron\n",
    "- Try a Perceptron model with more dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6c8002",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98dc9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b3991d",
   "metadata": {},
   "source": [
    "### Step 2: Read the data\n",
    "- Use Pandas [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) method to read **files/weather.csv**\n",
    "- HINT: Use **parse_dates=True** and **index_col=0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ef5aabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3337 entries, 2008-02-01 to 2017-06-25\n",
      "Data columns (total 22 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MinTemp        3334 non-null   float64\n",
      " 1   MaxTemp        3335 non-null   float64\n",
      " 2   Rainfall       3331 non-null   float64\n",
      " 3   Evaporation    3286 non-null   float64\n",
      " 4   Sunshine       3321 non-null   float64\n",
      " 5   WindGustDir    2301 non-null   object \n",
      " 6   WindGustSpeed  2301 non-null   float64\n",
      " 7   WindDir9am     3281 non-null   object \n",
      " 8   WindDir3pm     3304 non-null   object \n",
      " 9   WindSpeed9am   3311 non-null   float64\n",
      " 10  WindSpeed3pm   3312 non-null   float64\n",
      " 11  Humidity9am    3323 non-null   float64\n",
      " 12  Humidity3pm    3324 non-null   float64\n",
      " 13  Pressure9am    3317 non-null   float64\n",
      " 14  Pressure3pm    3318 non-null   float64\n",
      " 15  Cloud9am       2771 non-null   float64\n",
      " 16  Cloud3pm       2776 non-null   float64\n",
      " 17  Temp9am        3333 non-null   float64\n",
      " 18  Temp3pm        3333 non-null   float64\n",
      " 19  RainToday      3331 non-null   object \n",
      " 20  RISK_MM        3337 non-null   float64\n",
      " 21  RainTomorrow   3337 non-null   object \n",
      "dtypes: float64(17), object(5)\n",
      "memory usage: 599.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('files/weather.csv', parse_dates=True, index_col=0)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc2f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "276d6763",
   "metadata": {},
   "source": [
    "### Step 3: Investigate data\n",
    "- Look for missing data points\n",
    "- You can do that by applying **isna()** and **sum()**, which will give a summary of rows missing data for each column.\n",
    "    - Resource: [isna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html)\n",
    "    - Resource: [sum()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830debcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindGustDir      1036\n",
       "WindGustSpeed    1036\n",
       "Cloud9am          566\n",
       "Cloud3pm          561\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_missing = data.isnull().sum()\n",
    "# null count가 100 보다 큰 cols\n",
    "cols_with_missing[cols_with_missing > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69eaf04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01a32b51",
   "metadata": {},
   "source": [
    "### Step 4: Remove 'dirty' columns \n",
    "- Make a choice and remove columns with too many entries with NaN.\n",
    "- Say, take all columns with more than 100 rows.\n",
    "- Also, you can remove rows with non-numeric values (remember to keep **RainTomorrow**)\n",
    "- To remove rows use [drop(columns, axis=1)](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "444b30a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.copy()\n",
    "# null count가 100 보다 큰 cols를 drop\n",
    "dataset.drop(['WindGustDir', 'WindGustSpeed', 'Cloud9am', 'Cloud3pm'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1082f71",
   "metadata": {},
   "source": [
    "- [select_dtypes](https://stackoverflow.com/questions/48817592/how-to-drop-dataframe-columns-based-on-dtype)\n",
    "- [api](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "578fc564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3337 entries, 2008-02-01 to 2017-06-25\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   MinTemp       3334 non-null   float64\n",
      " 1   MaxTemp       3335 non-null   float64\n",
      " 2   Rainfall      3331 non-null   float64\n",
      " 3   Evaporation   3286 non-null   float64\n",
      " 4   Sunshine      3321 non-null   float64\n",
      " 5   WindSpeed9am  3311 non-null   float64\n",
      " 6   WindSpeed3pm  3312 non-null   float64\n",
      " 7   Humidity9am   3323 non-null   float64\n",
      " 8   Humidity3pm   3324 non-null   float64\n",
      " 9   Pressure9am   3317 non-null   float64\n",
      " 10  Pressure3pm   3318 non-null   float64\n",
      " 11  Temp9am       3333 non-null   float64\n",
      " 12  Temp3pm       3333 non-null   float64\n",
      " 13  RISK_MM       3337 non-null   float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 520.1 KB\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.select_dtypes(exclude=['object'])\n",
    "dataset.info() # RainTomorrow가 gone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac473dd7",
   "metadata": {},
   "source": [
    "### Step 5: Deal with remaining missing data\n",
    "- A simple choice is to simply remove rows with missing data\n",
    "- Use [dropna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c659169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e408df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5db49d8e",
   "metadata": {},
   "source": [
    "### Step 6: Create training and test datasets\n",
    "- Define dataset **X** to consist of all data except **'RainTomorrow'**.\n",
    "    - Use [dropna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)\n",
    "- Define dataset **y** to be datset cosisting of **'RainTomorrow'**.\n",
    "- Divide into **X_train, X_test, y_train, y_test** with **train_test_split**\n",
    "    - You can use **random_state=42** (or any other number) if you want to reproduce results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b56151b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a139c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "809734e0",
   "metadata": {},
   "source": [
    "### Step 7: Train and test the model\n",
    "- Create classifier with **Perceptron**\n",
    "    - You can use **random_state=0** to be able to reproduce\n",
    "- Fit the model with training data **(X_train, y_train**)\n",
    "- Predict data from **X_test** (use predict) and assign to **y_pred**.\n",
    "- Evalute score by using **metrics.accuracy_score(y_test, y_pred)**.\n",
    "- You can redo with different choice of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e062506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173d904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56f51ce7",
   "metadata": {},
   "source": [
    "### Step 8 (Optional): Plot the result\n",
    "- Use Matplotlib.pyplot (**plt**) with **subplots** to create a figure and axes (**fig, ax**)\n",
    "- Predict all the datapoints in **X**.\n",
    "- Make a scatter plot with all datapoints in **X** with color by the predictions made.\n",
    "    - You might want to use **alpha=0.25** in your plot as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e567f37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b296e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c76c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
